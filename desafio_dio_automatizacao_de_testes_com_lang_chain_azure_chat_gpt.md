# Desafio DIO ‚Äî Automatiza√ß√£o da cria√ß√£o de testes unit√°rios com LangChain + Azure ChatGPT

## üìå Vis√£o Geral

Este reposit√≥rio demonstra como utilizar **LangChain** e **Azure OpenAI (ChatGPT)** para automatizar a cria√ß√£o de testes unit√°rios em Python. O processo analisa fun√ß√µes e gera automaticamente arquivos de teste (`pytest`).

**Principais recursos:**
- Gera√ß√£o autom√°tica de testes via LangChain + Azure ChatGPT.
- Estrutura modular para f√°cil expans√£o.
- Integra√ß√£o com GitHub Actions para CI/CD.

---

## Estrutura do Reposit√≥rio

```
‚îú‚îÄ .github/workflows/tests.yml   # Pipeline GitHub Actions
‚îú‚îÄ .gitignore
‚îú‚îÄ README.md
‚îú‚îÄ requirements.txt
‚îú‚îÄ .env.example
‚îú‚îÄ src/
‚îÇ  ‚îú‚îÄ app/
‚îÇ  ‚îÇ  ‚îî‚îÄ sample_module.py        # Fun√ß√µes de exemplo
‚îÇ  ‚îú‚îÄ tests_generated/           # Sa√≠da dos testes gerados
‚îÇ  ‚îî‚îÄ generate_tests.py          # Script principal
‚îî‚îÄ images/                       # (opcional) Screenshots
```

---

## Pr√©-requisitos
- Python 3.10+
- Conta Azure OpenAI com chave e endpoint
- `pip install -r requirements.txt`

**requirements.txt:**
```
langchain>=0.0.200
openai>=0.27.0
python-dotenv
pytest
requests

aiohttp
```

---

## Configura√ß√£o
1. Renomeie `.env.example` para `.env` e configure:
```
AZURE_OPENAI_API_KEY=YOUR_KEY
AZURE_OPENAI_ENDPOINT=https://your-resource-name.openai.azure.com/
AZURE_OPENAI_DEPLOYMENT_NAME=gpt-4o-chat
```

---

## C√≥digo de Exemplo

**src/app/sample_module.py**
```python
def soma(a: int, b: int) -> int:
    return a + b

def divide(a: float, b: float) -> float:
    return a / b
```

**src/generate_tests.py**
```python
import os
from dotenv import load_dotenv
from langchain.chat_models import AzureChatOpenAI
from langchain.prompts import ChatPromptTemplate
from langchain.chains import LLMChain

load_dotenv()

llm = AzureChatOpenAI(
    deployment_name=os.getenv("AZURE_OPENAI_DEPLOYMENT_NAME"),
    openai_api_base=os.getenv("AZURE_OPENAI_ENDPOINT"),
    openai_api_key=os.getenv("AZURE_OPENAI_API_KEY"),
    temperature=0.0,
    max_tokens=1000,
)

PROMPT = """
Voc√™ √© um gerador de testes unit√°rios em Python (pytest).
C√≥digo:
```
{source_code}
```
Gere o conte√∫do do arquivo de teste.
"""

prompt = ChatPromptTemplate.from_template(PROMPT)
chain = LLMChain(llm=llm, prompt=prompt)

def generate_tests_for_source(source_code: str) -> str:
    return chain.run(source_code=source_code)

if __name__ == "__main__":
    with open("src/app/sample_module.py", "r") as f:
        source = f.read()
    tests_code = generate_tests_for_source(source)
    os.makedirs("src/tests_generated", exist_ok=True)
    with open("src/tests_generated/test_sample_module.py", "w") as fo:
        fo.write(tests_code)
    print("Testes gerados em src/tests_generated/")
```

---

## Execu√ß√£o Local
```bash
python -m venv .venv && source .venv/bin/activate
pip install -r requirements.txt
python src/generate_tests.py
pytest src/tests_generated -q
```

---

## GitHub Actions

**.github/workflows/tests.yml**
```yaml
name: Generate and Run Tests
on: [push]

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - uses: actions/setup-python@v4
        with:
          python-version: '3.10'
      - run: pip install -r requirements.txt
      - run: python src/generate_tests.py
        env:
          AZURE_OPENAI_API_KEY: ${{ secrets.AZURE_OPENAI_API_KEY }}
          AZURE_OPENAI_ENDPOINT: ${{ secrets.AZURE_OPENAI_ENDPOINT }}
          AZURE_OPENAI_DEPLOYMENT_NAME: ${{ secrets.AZURE_OPENAI_DEPLOYMENT_NAME }}
      - run: pytest src/tests_generated -q
```

---



